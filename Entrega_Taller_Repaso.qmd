---
title: "Taller evaluado de repaso para el Primer Parcial - Àngela Martí Calatayud"
subtitle: "20582- Análisis de Datos para el GMAT"
format:
  html:
    theme: lumen
    toc: true
    toc-depth: 3
Rendering:
    embed-resources: true
editor: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r, echo=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(GGally)
library(Hotelling)
library(MASS)
library(readr)
library(tidyr)
```

El cambio climático está provocando un aumento en la temperatura media global, lo que a su vez incrementa la frecuencia y severidad de fenómenos meteorológicos extremos, como olas de calor y lluvias intensas, como hemos visto esta última semana en Valencia.

En primer lugar, vamos a analizar la tendéncia de la temperatura media global, és decir, vamos a: 
- Examinar la evolución de la temperatura global a lo largo del periodo simulado (por ejemplo, de 2000 a 2023).
- Confirmar si hay un incremento significativo en la temperatura media anual, lo cual es fundamental para explorar su posible relación con los fenómenos extremos.
Para ello, haremos un análisis de series temporales y regresión lineal para identificar una tendencia significativa en los datos de temperatura global. prueva

Seguidamente, estudiaremos la frecuencia de fenómenos meteorológicos extremos a lo largo del tiempo: - Cuantificaremos el número de días con temperaturas extremas (olas de calor) y de eventos de lluvias intensas en cada año del periodo simulado.
-Observaremos si hay un patrón creciente en la ocurrencia de estos fenómenos en las últimas décadas.
Haremos gráficos de frecuencia anual y regresión para observar tendencias en la cantidad de fenómenos extremos.

Después, examinamos la relación entre el aumento de la temperatura global y la frecuencia de fenómenos extremos, para ello: - Se analizar si los años con mayores temperaturas medias globales coinciden con una mayor frecuencia de fenómenos extremos.
- Se evaluar la relación entre los incrementos en la temperatura global y la ocurrencia de olas de calor y lluvias intensas.
La técnica, serà un análisis de correlación entre la temperatura media anual y la frecuencia de fenómenos extremos.

Seguidamente, cuantificaremos la magnitud del impacto del cambio climático en la frecuencia de fenómenos extremos, donde se: - Calcula el grado en el que el aumento de la temperatura media global está asociado con el incremento de fenómenos extremos.
- Proporcionar una estimación de cuántos eventos extremos adicionales se podrían atribuir al aumento de cada grado en la temperatura global.
Técnica sugerida: Modelos de regresión lineal o Poisson para cuantificar el impacto directo del cambio de temperatura en la frecuencia de fenómenos.
Evaluar posibles limitaciones del análisis:

Finalmente, identificaremos posibles limitaciones en la simulación de datos y en la interpretación de los resultados, especialmente dado el uso de datos simulados.I proporcionaremos sugerencias para análisis futuros con datos reales y posibles mejoras en la metodología.

# Definición de las variables

En primer lugar, vamos a definir la variables clave para nuestra hipòtesis, donde tendremos cuatro variables cuantitativas, tres ordinales y dos nominales, que són: 
  - Variables Ordinales:
    - Temperatura Media Global Anual (ºC)
    - Número de Días de Olas de Calor (días)
    - Número de Días de Lluvias Intensas (días)
    - Precipitación Anual Total en milímetros (mm)
  - Variables Cualitativas (hacer mosaico) 
    - Severidad de las Olas de Calor (Baja, Moderada, Alta, Extrema)
    - Intensidad de Lluvias Intensas (Baja, Moderada, Alta)
    - Período de Tiempo ("1980-1990", "1991-2000", "2001-2010", "2011-2020")
  - Variables Nominales
    - Región Geográfica (América del Norte, Europa, Asia, América Latina, África)
    - Tipo de Evento (Ola de Calor, Lluvia Intensa, Sequía, Inundación)

Seguidamente, generaramos una tabla, que la llamaremos como tabla1, con al menos 100 abservaciones, donde las variables cuantitativas sigan una distribución normal multivariante.

```{r, echo=FALSE}
media <- c(15, 100, 50, 850)  # Medias de temp_global, dias_calor, dias_lluvia, precipitacion_total
covarianza <- matrix(c(0.1, 0.05, 0.07, 1.5,
                       0.05, 4, 2, 5,
                       0.07, 2, 6, 7,
                       1.5, 5, 7, 200), 
                     nrow = 4, ncol = 4)

# Generar los datos con distribución normal multivariante
set.seed(123)  # Fijar semilla para reproducibilidad
datos_numericos <- mvrnorm(150, mu = media, Sigma = covarianza)

# Limitar y ajustar valores en las variables
# Redondear temp_global a una decimal, heatwaves y heavy_rain a enteros, y precipitation_total a enteros
datos_numericos[,1] <- round(datos_numericos[,1], 1)   # Temp_global en grados Celsius
datos_numericos[,2] <- round(pmax(datos_numericos[,2], 0)) # dias_calor en días, mínimo de 0 días
datos_numericos[,3] <- round(pmax(datos_numericos[,3], 0)) # dias_lluvia en días, mínimo de 0 días
datos_numericos[,4] <- round(pmax(datos_numericos[,4], 0)) # precipitacion_total en mm, mínimo de 0


# Crear una tabla de datos completa con las variables adicionales
# Asignación de variables nominales y ordinales
tabla1 <- data.frame(
  temp_global1 = datos_numericos[,1],             # Temperatura Media Global Anual (°C)
  dias_calor1 = datos_numericos[,2],               # Número de Días de Olas de Calor (días)
  dias_lluvia1 = datos_numericos[,3],              # Número de Días de Lluvias Intensas (días)
  precipitacion_total1 = datos_numericos[,4],     # Precipitación Anual Total (mm)
  region1 = sample(c("América del Norte", "Europa", "Asia", "América Latina", "África"), 150, replace = TRUE),
  tipo_evento1 = sample(c("Ola de Calor", "Lluvia Intensa", "Sequía", "Inundación"), 150, replace = TRUE),
  ola_calor1 = ordered(sample(1:4, 150, replace = TRUE), labels = c("Baja", "Moderada", "Alta", "Extrema")),
  lluvia_intensa1 = ordered(sample(1:3, 150, replace = TRUE), labels = c("Baja", "Moderada", "Alta")),
  periodo_de_tiempo1 = ordered(sample(1:4, 150, replace = TRUE), labels = c("1980-1990", "1991-2000", "2001-2010", "2011-2020"))
)


# Ordenar por 'region1' y añadir columna de identificador
tabla1 <- tabla1 %>%
  arrange(region1) %>%             # Ordenar por región
  mutate(id = row_number()) %>%     # Añadir identificador único
  dplyr::select(id, everything())          # Mover 'id' a la primera columna

# Ver las primeras filas para verificar
#head(tabla1)

```
# Gràfico Mosaico_Tabla1

```{r}
# Convertir a tabla de frecuencias de dos variables categóricas
tabla_frecuencias <- table(tabla1$region1, tabla1$tipo_evento1)

# Crear el gráfico de mosaico
mosaicplot(tabla_frecuencias, main = "Distribución de Eventos por Región",
           xlab = "Región", ylab = "Tipo de Evento", color = TRUE)


```



Sguidamente, a partir de [Kaggle](https://www.kaggle.com/), hemos extraído un .csv llamamodo como climate_change_indicators.csv de donde nos quedamos solo con la variable temperatura global per cada uno de los años, que són desde el 1961 hasta el 2022.

```{r}
tabla2 <- read_csv("climate_change_indicators.csv")

# Crear el mapeo de países a regiones
region_paises <- list(
  "America Latina" = c("Argentina", "Bolivia", "Brazil", "Chile", "Colombia", "Costa Rica", "Cuba", 
                      "Barbados", "Belize", "Bolivia", 
                      "Brazil", "British Virgin Islands", "Cayman Islands", 
                          "Chile", "Colombia", "Costa Rica", "Cuba", "Dominica", 
                          "Dominican Rep.", "Ecuador", "El Salvador", 
                          "Falkland Islands (Malvinas)", "Grenada", "Guadeloupe", 
                          "Guatemala", "Guyana", "Haiti", "Honduras", 
                          "Jamaica", "Martinique", "Mexico", "Montserrat", 
                          "Nicaragua", "Panama", "Paraguay", "Peru",  "Grenada"),
  "America del Norte" = c("United States", "Canada", "Mexico", "Bermuda", "Greenland", "French Polynesia", "Kiribati",        
             "Micronesia, Federated States of", "Nauru, Rep. of", 
             "New Caledonia", "New Zealand", "Niue", "Norfolk Island", 
             "Palau, Rep. of", "Papua New Guinea", "Samoa", 
             "Solomon Islands", "Tokelau", "Tonga", "Saint Pierre and Miquelon"), #para que haya mas datos cogemos también los de Oceania aquí dentro
  "Asia" = c("China", "India", "Japan", "South Korea", "Indonesia", "Pakistan", "Bangladesh", 
             "Vietnam", "Philippines", "Iran", "Turkey", "Thailand", "Myanmar", "Iraq", 
             "Afghanistan", "Saudi Arabia", "Uzbekistan", "Malaysia", "Yemen", "Nepal", 
             "Sri Lanka", "Kazakhstan", "Syria","Afghanistan, Islamic Rep. of", "Armenia, Rep. of", "Azerbaijan, Rep. of", 
          "Korea, Rep. of", "Kuwait", "Kyrgyz Rep.", "Lao People's Dem. Rep.", 
          "Malaysia", "Maldives", "Mongolia", "Myanmar", "Nepal", 
          "Thailand", "Tajikistan", "Israel", "Laos", "Lebanon", "Kyrgyzstan", 
             "Turkmenistan", "Singapore", "Oman", "State of Palestine"),
  "Europa" = c("United Kingdom", "Germany", "France", "Italy", "Spain", "Ukraine", "Poland", 
               "Romania", "Netherlands", "Belgium", "Czech Republic", "Greece", "Portugal", 
               "Sweden", "Hungary", "Belarus", "Austria", "Switzerland", "Bulgaria", "Serbia", 
               "Denmark", "Finland", "Albania", "Andorra, Principality of", "Austria", "Belarus, Rep. of", 
            "Italy", "Latvia", "Liechtenstein", "Lithuania", 
            "Luxembourg", "Malta", "Moldova, Rep. of", "Monaco", 
            "Montenegro", "Netherlands, The", "North Macedonia, Republic of", 
            "Norway", "Poland, Rep. of", "Portugal", "Romania", 
            "Russian Federation", "San Marino, Rep. of", "Serbia, Rep. of", 
            "Bosnia and Herzegovina", "Albania", "Lithuania", "North Macedonia", "Slovenia", 
               "Latvia", "Estonia", "Luxembourg", "Malta", "Iceland", "Andorra", "Monaco", 
               "Liechtenstein", "San Marino"),
  "Africa" = c("Nigeria", "Ethiopia", "Egypt", "DR Congo", "Tanzania", "South Africa", "Kenya", 
               "Uganda", "Algeria", "Sudan", "Morocco", "Angola", "Mozambique", "Ghana", 
               "Madagascar", "Cameroon", "Côte d'Ivoire", "Niger", "Burkina Faso", "Mali", 
               "Malawi", "Zambia", "Senegal", "Chad", "Somalia", "Zimbabwe", "Guinea", 
               "Rwanda", "Benin", "Burundi", "Tunisia", "South Sudan", "Togo", "Sierra Leone", 
               "Libya", "Congo", "Liberia", "Central African Republic", "Mauritania", "Eritrea", 
               "Namibia", "Gambia", "Botswana", "Burkina Faso", 
            "Burundi", "Cabo Verde", "Cameroon", "Central African Rep.", 
            "Chad", "Comoros, Union of the", "Congo, Dem. Rep. of the", 
            "Congo, Rep. of", "Djibouti", "Egypt, Arab Rep. of", 
            "Equatorial Guinea, Rep. of", "Eritrea, The State of", 
            "Eswatini, Kingdom of", "Ethiopia, The Federal Dem. Rep. of", 
            "Gabon", "Gambia, The", "Ghana", "Guinea", "Guinea-Bissau", 
            "Ivory Coast", "Kenya", "Lesotho, Kingdom of", "Liberia", 
            "Libya", "Madagascar, Rep. of", "Malawi", "Mali", 
            "Mauritania, Islamic Rep. of", "Mauritius", "Morocco", 
            "Mozambique, Rep. of", "Namibia", "Niger", "Nigeria", 
            "Rwanda", "São Tomé and Príncipe, Dem. Rep. of", 
            "Senegal", "Seychelles", "Sierra Leone", "Somalia", 
            "South Africa", "South Sudan, Rep. of", "Sudan", 
            "Tanzania, United Rep. of", "Togo", "Tunisia", 
            "Uganda", "Zambia", "Zimbabwe", "Gabon", "Lesotho", "Eswatini", "Guinea-Bissau", 
               "Equatorial Guinea", "Seychelles", "Sao Tome and Principe", "Comoros", "Cabo Verde")
)

# Crear un dataframe para el mapeo de regiones
region_df <- stack(region_paises)
colnames(region_df) <- c("Country", "region")

# Unir el mapeo con los datos
data2 <- merge(tabla2, region_df, by.x = "Country", by.y = "Country", all.x = TRUE)

# Filtrar y ordenar los datos por región y país
tabla2 <- data2 %>%
  dplyr::select(Country, region, F2021, F2022) %>%
  filter(!is.na(region)) %>%
  arrange(region, Country)

# Añadir una columna de identificador
data_final <- tabla2 %>%
  mutate(id = row_number()) %>%  # Añadir ID secuencial
  dplyr::select(id, everything())  # Eliminar 'Country' y reordenar

data_final<- data_final %>%
  dplyr::select(-Country)

# Ordenar por región y luego por el identificador
tabla2 <- data_final %>%
  arrange(id, region)

# Mostrar los primeros resultados
head(tabla2, 10)

```




Finalmente, uniremos la dos tablas creados creando unatabla unificada a partir de la cual haremos el analisi para extraer las conclusiones.

```{r, echo=FALSE}

# Unir ambas tablas por el identificador común 'id'
tabla_combinada <- tabla1 %>%
  left_join(tabla2, by = "id")
tabla_combinada <- tabla_combinada %>%
  drop_na()
# Verificar las primeras filas de la tabla combinada
head(tabla_combinada)

# Resumen de la tabla combinada
#summary(tabla_combinada)
#No hay alguna manera de juntar años con el periodo del tiempo?
```



# Análisis descriptivo multivariantes

Ahora, vamos a realiza un análisis descriptivo multivariantes de tu base de datos. 
Paso 1: Análisis Descriptivo de Variables Cuantitativas

```{r, echo=FALSE}
#Matriz de correlación (sin especificar nombres, seleccionando automáticamente solo las columnas numéricas)
matriz_correlacion <- tabla_combinada %>% 
  select_if(is.numeric) %>% 
  cor()
#print(matriz_correlacion)

#Visualización de la correlación con ggpairs (sin especificar nombres)
ggpairs(tabla_combinada %>% 
          dplyr::select(-id) %>%
          select_if(is.numeric), 
        title = "Matriz de Gráficos de Pares de Variables Cuantitativas")

```


Paso 2: Análisis de Variables Categóricas

```{r, echo=FALSE}
# Gráfico de barras para variables ordinales y nominales
#Gráfico de barras para la variable "tipo_evento"
tabla_combinada %>%
  ggplot(aes(x = tipo_evento1)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Distribución de Tipos de Eventos", x = "Tipo de Evento", y = "Frecuencia") +
  theme_minimal()

#ráfico de barras para la variable "olas de calor"
tabla_combinada %>%
  ggplot(aes(x = ola_calor1)) +
  geom_bar(fill = "salmon") +
  labs(title = "Distribución de Severidad de Olas de Calor", x = "Severidad", y = "Frecuencia") +
  theme_minimal()
```


Paso 3: Visualización de Relaciones entre Variables

```{r, echo=FALSE}
#Boxplot para analizar la temperatura global por tipo de evento
tabla_combinada %>%
  ggplot(aes(x = tipo_evento1, y = temp_global1, fill = tipo_evento1)) +
  geom_boxplot() +
  labs(title = "Distribución de Temperatura Global por Tipo de Evento", x = "Tipo de Evento", y = "Temperatura Global (°C)") +
  theme_minimal()

#Gráfico de dispersión para analizar la relación entre la precipitación total y la temperatura global, coloreando por tipo de evento
tabla_combinada %>%
  ggplot(aes(x = precipitacion_total1, y = temp_global1, color = tipo_evento1)) +
  geom_point(alpha = 0.7) +
  labs(title = "Relación entre Precipitación Total y Temperatura Global",
       x = "Precipitación Total (mm)", y = "Temperatura Global (°C)") +
  theme_minimal()
```


Seguidamente, selectionamos la variable "tipo_evento" i la modelízamos con una distribución multinomial, para así, estimar sus parámetros.

Primero, calculamos las probabilidad de cada tipo de evento:

```{r, echo=FALSE}
# Frecuencia relativa de cada tipo de evento en la variable tipo_evento
probabilidades_evento <- tabla_combinada %>%
  count(tipo_evento1) %>%
  mutate(probabilidad = n / sum(n))

probabilidades_evento
```

Seguidamente, extraemos las probabilidades en un vector para la distribución multinomial, i después simulamos una muestra de tamaño 20 usando distribución multinomial, lo qual genera el número esperado de cada tipo de evento en dicha muestra de tamaño 20.

```{r, echo=FALSE}
probs <- probabilidades_evento$probabilidad #extraemos probabilidad
set.seed(42)  # Fijar semilla para reproducibilidad
muestra_multinomial <- rmultinom(n = 1, size = 20, prob = probs) #Simular una muestra de tamaño 20 usando distribución multinomial

# Mostrar resultados de la muestra multinomial
rownames(muestra_multinomial) <- probabilidades_evento$tipo_evento1
colnames(muestra_multinomial) <- c("Simulación")
print(muestra_multinomial)
```

Ahora, calcularmos la probabilidad de un evento de interés, por ejemplo "Ola de Calor", dicha muestra ha de ser de tamaño 20.

```{r, echo=FALSE}
# Probabilidad de observar al menos una "Ola de Calor" en la muestra de tamaño 20
evento_interes <- "Ola de Calor"

# Probabilidad de que ocurra al menos una "Ola de Calor" en la muestra
prob_evento_interes <- 1 - dbinom(0, size = 20, prob = probs[probabilidades_evento$tipo_evento1 == evento_interes])
cat("La probabilidad de observar al menos una 'Ola de Calor' en una muestra de tamaño 20 es:", prob_evento_interes, "\n")

```

Este análisis nos permite evaluar la probabilidad de ocurrencia de eventos específicos en una muestra, lo cual es útil para comprender la frecuencia esperada de eventos extremos en el contexto del cambio climático.

# Modelo de regresión multivariante

Ahora, con las variables cuantitativas de nuestra base de datos, ajustaremos un modelo de regresión multivariante en la forma:

$$Y=\beta_0+\beta_1 X_1+ \cdots + \beta_p X_p + \epsilon$$ Donde $Y$ es la variable cuantitativa que deseamos explicar en función del resto de variables cuantitativas registradas, es decir, la variable dependiente que en nustro caso sera "temp_global" y 'dias_calor', 'dias_lluvia', y 'precipitacion_total' son las variables independientes (X_1, X_2, X_3).

"El score es la diferencia entre los valores observados y los valores predichos por el modelo, lo que se conoce como residuales. Analizaremos los residuales para evaluar la precisión y ajuste del modelo."

```{r, echo=FALSE}
# Ajuste del modelo de regresión
modelo <- lm(temp_global1 ~ dias_calor1 + dias_lluvia1 + precipitacion_total1, data = tabla_combinada)

# Resumen del modelo para ver los coeficientes y el ajuste
#summary(modelo)

# Cálculo de la función de score: los residuales del modelo
residuales <- resid(modelo)

# Interpretación del score en el contexto del problema
cat("Los primeros valores de los residuales (score) son:\n")
print(head(residuales))

# Evaluación gráfica de los residuales
# Histograma de los residuales para ver su distribución
hist(residuales, main = "Distribución de los Residuales", xlab = "Residuales", col = "lightblue", border = "black")

# Gráfico de dispersión de los valores predichos vs los residuales
# Para observar si hay alguna tendencia o patrón en los errores
plot(modelo$fitted.values, residuales,
     main = "Valores Predichos vs Residuales",
     xlab = "Valores Predichos",
     ylab = "Residuales",
     col = "blue", pch = 16)
abline(h = 0, col = "red", lwd = 2)


```
# Distancia de Mahalon

```{r}
# Asegurarse de que la tabla combinada es solo numérica (o selecciona columnas numéricas)
datos_num <- tabla_combinada %>% 
  select_if(is.numeric)  # Selecciona solo las columnas numéricas para el análisis

# 1. Calcular la distancia de Mahalanobis para los datos originales
# Esto calcula la distancia de Mahalanobis al cuadrado
dist_mahalanobis <- mahalanobis(datos_num, colMeans(datos_num), cov(datos_num))

# Añadir las distancias de Mahalanobis como una nueva columna en la tabla combinada
tabla_combinada_maha <- tabla_combinada %>%
  mutate(mahalanobis_d2 = dist_mahalanobis)

# 2. Definir la matriz de transformación T y aplicarla a los datos numéricos
T <- matrix(c(1.2, 0.3, 0.0,
              0.2, 1.1, 0.0,
              0.0, 0.0, 1.5), nrow = ncol(datos_num), byrow = TRUE)

# Asegurarse de que la matriz T tenga el mismo número de columnas que datos_num
if(ncol(datos_num) != nrow(T)) {
  stop("El número de columnas en 'datos_num' debe coincidir con el número de filas en 'T'")
}

# Aplicar la transformación a los datos numéricos
datos_transformados <- as.matrix(datos_num) %*% T

# 3. Calcular la distancia de Mahalanobis en los datos transformados
dist_mahalanobis_transformado <- mahalanobis(datos_transformados, colMeans(datos_transformados), cov(datos_transformados))

# Añadir la distancia de Mahalanobis transformada a la tabla combinada
tabla_combinada_maha <- tabla_combinada_maha %>%
  mutate(mahalanobis_d2_transformado = dist_mahalanobis_transformado)

# Ver las primeras filas con las distancias
head(tabla_combinada_maha)





```


```{r}
# Cargar la librería necesaria para la visualización
library(ggplot2)

# Número de variables (grados de libertad), es decir, el número de columnas en datos_num
k <- ncol(datos_num)

# Histograma para la distancia de Mahalanobis original
ggplot(tabla_combinada_maha, aes(x = mahalanobis_d2)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  stat_function(fun = dchisq, args = list(df = k), color = "red", size = 1.5) +
  labs(title = "Distribución de Distancias Mahalanobis al Cuadrado (Original)",
       subtitle = paste("Comparación con la distribución Chi-cuadrado con", k, "grados de libertad"),
       x = "Distancia Mahalanobis al Cuadrado",
       y = "Densidad") +
  theme_minimal()

# Histograma para la distancia de Mahalanobis transformada
ggplot(tabla_combinada_maha, aes(x = dist_mahalanobis_transformado)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  stat_function(fun = dchisq, args = list(df = k), color = "red", size = 1.5) +
  labs(title = "Distribución de Distancias Mahalanobis al Cuadrado (Transformada)",
       subtitle = paste("Comparación con la distribución Chi-cuadrado con", k, "grados de libertad"),
       x = "Distancia Mahalanobis Transformada al Cuadrado",
       y = "Densidad") +
  theme_minimal()


```


```{r}
# Prueba estadística para confirmar distribución ji-cuadrado
ks.test(dist_mahalanobis, "pchisq", df = 3)

```











```{r}
# Seleccionar solo las columnas numéricas
datos_num <- tabla_combinada %>% select_if(is.numeric)

# Verificar si hay valores NA
#summary(datos_num)

# Eliminar filas con valores NA
#datos_num <- na.omit(datos_num)

# Calcular la distancia Mahalanobis al cuadrado
mahalanobis_d2 <- apply(datos_num, 1, function(x) {
  mahalanobis(x, center = colMeans(datos_num), cov = cov(datos_num))^2
})

tabla_combinada$mahalanobis_d2 <- mahalanobis_d2

# Verificar que la columna 'mahalanobis_d2' tiene valores
head(mahalanobis_d2)


```
```{r}
# Asumiendo que tus distancias de Mahalanobis al cuadrado están en la variable `mahalanobis_d2`

# Verificar que la columna mahalanobis_d2 es numérica
str(tabla_combinada$mahalanobis_d2)

# Si no es un vector numérico, convertirlo a numérico:
tabla_combinada$mahalanobis_d2 <- as.numeric(tabla_combinada$mahalanobis_d2)

# Eliminar cualquier valor NA en caso de que existan
#tabla_combinada <- tabla_combinada %>% filter(!is.na(mahalanobis_d2))

# Verificar la distribución de las distancias
summary(tabla_combinada$mahalanobis_d2)

# Número de variables (grados de libertad) - k
k <- ncol(datos_num)

# Crear el histograma de las distancias Mahalanobis al cuadrado
hist(tabla_combinada$mahalanobis_d2, 
     breaks = 20,                          # Número de "barras" en el histograma
     col = "skyblue",                      # Color de las barras
     border = "black",                     # Color del borde de las barras
     probability = TRUE,                    # Normaliza el histograma para que sea una densidad
     main = "Distribución de Distancias Mahalanobis al Cuadrado",  # Título del gráfico
     xlab = "Distancia Mahalanobis al Cuadrado",  # Etiqueta del eje x
     ylab = "Densidad")                    # Etiqueta del eje y

# Agregar la curva de la distribución Chi-cuadrado con k grados de libertad
curve(dchisq(x, df = k), 
      col = "red",                        # Color de la curva
      lwd = 2,                            # Grosor de la línea de la curva
      add = TRUE)                         # Agregar la curva sobre el histograma

```


```{r}
# Calcular las distancias Mahalanobis al cuadrado
k <- ncol(datos_num)  # Número de variables (grados de libertad)

mahalanobis_d2 <- datos_num %>%
  as.matrix() %>%
  apply(1, function(x) mahalanobis(x, center = colMeans(datos_num), cov = cov(datos_num))^2)

# Añadir las distancias al data frame original
tabla_combinada <- tabla_combinada %>%
  mutate(mahalanobis_d2 = mahalanobis_d2)


# Ver las primeras filas con las distancias
head(tabla_combinada)

# Número de variables numéricas (esto es k, los grados de libertad)
k <- ncol(datos_num)

# Histograma de las distancias Mahalanobis al cuadrado
ggplot(tabla_combinada, aes(x = mahalanobis_d2)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  # Agregar la curva de la distribución Chi-cuadrado con k grados de libertad
  stat_function(fun = dchisq, args = list(df = k), color = "red", size = 1.5) +
  labs(title = "Distribución de Distancias Mahalanobis al Cuadrado",
       subtitle = paste("Comparación con la distribución Chi-cuadrado con", k, "grados de libertad"),
       x = "Distancia Mahalanobis al Cuadrado",
       y = "Densidad") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Planteamiento del Contraste de Hipótesis**

Queremos evaluar si existe una diferencia significativa en el vector de medias de las variables climáticas cuantitativas (`temp_global`, `dias_calor`, `dias_lluvia`, y `precipitacion_total`) entre dos tipos de eventos climáticos: "Ola de Calor" y "Sequía".

*Planteamiento del Contraste de Hipótesis*

Definimos las hipótesis nula y alternativa de la siguiente manera:

$$
H_0: \mu_{\text{Ola de Calor}} = \mu_{\text{Sequía}}
$$

$$
H_1: \mu_{\text{Ola de Calor}} \neq \mu_{\text{Sequía}}
$$

Donde: - ( \mu*{*\text{Ola de Calor}} ) es el vector de medias de las variables cuantitativas para los eventos de tipo "Ola de Calor".
- ( \mu{\text{Sequía}} ) es el vector de medias de las variables cuantitativas para los eventos de tipo "Sequía".

En este contraste de hipótesis, usamos la prueba de Hotelling's ( T\^2 ) para evaluar si existe una diferencia significativa entre los vectores de medias multivariantes.

**Ejecución del Contraste de Hipótesis en R**

```{r, echo=FALSE}
# Filtrar los datos para el grupo de eventos de "Ola de Calor"
calor <- tabla_combinada %>%
  filter(tipo_evento1 == "Ola de Calor")

# Filtrar los datos para el grupo de eventos de "Sequía"
sequia <- tabla_combinada %>%
  filter(tipo_evento1 == "Sequía")

# Realizar el contraste de Hotelling usando solo las variables cuantitativas de interés
resultado_hotelling <- hotelling.test(calor[, c("temp_global1", "dias_calor1", "dias_lluvia1", "precipitacion_total1")],
                                      sequia[, c("temp_global1", "dias_calor1", "dias_lluvia1", "precipitacion_total1")])

# Ver los resultados del contraste
print(resultado_hotelling)

```

**Interpretación de Resultados** 
Según el resultado del contraste de Hotelling:

Si $p_{valor} < 0.05$: Rechazamos la hipótesis nula y concluimos que existe una diferencia significativa en el vector de medias para los eventos de tipo "Ola de Calor" y "Sequía".
Si $p_{valor} ≥ 0.05$: No rechazamos la hipótesis nula, lo cual indica que no encontramos evidencia suficiente para afirmar que las medias de las variables cuantitativas son diferentes entre los dos tipos de eventos.

Por lo tanto, como el p_valor es $0.9672$, tenemos que no podemos rechazar la hipotesis nula.Esto significa que no hay evidencia estadística suficiente para afirmar que las medias de las variables cuantitativas son significativamente diferentes entre los dos tipos de eventos ("Ola de Calor" y "Sequía").

Aunque el valor p es alto, es importante recordar que esta conclusión depende de la calidad de los datos, el tamaño de la muestra y los supuestos del modelo.
Si tienes dudas sobre la calidad de los datos o el tamaño de la muestra, puedes considerar revisar esos aspectos para fortalecer el análisis.














